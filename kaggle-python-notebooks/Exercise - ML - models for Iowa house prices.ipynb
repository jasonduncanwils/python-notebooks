{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "e81ee64d-e474-4662-9036-ce23df615199",
        "_uuid": "b6269c0e8f417f82daf093dda8fa0da6d2c57d86"
      },
      "cell_type": "markdown",
      "source": "This notebook is based on the lessons on machine learning that Kaggle curates at https://www.kaggle.com/learn/overview.\n\nThis first section starts out with a lot of data prep and discovery."
    },
    {
      "metadata": {
        "scrolled": false,
        "_cell_guid": "86b26423-563a-4fa1-a595-89e25ff93089",
        "_uuid": "1c728098629e1301643443b1341556a15c089b2b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nfrom sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import Imputer\nfrom xgboost import XGBRegressor\n\n# defined function to get mean absolute error for decision tree\ndef get_decision_depth_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)\n\n# defined function to get mean absolute error for random forest\ndef get_forest_mae(X_train, X_test, y_train, y_test):\n    model = RandomForestRegressor()\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    mae = mean_absolute_error(y_test, preds)\n    return(mae)\n\n# another way to check MAE with sklearn\ndef get_forest_mae2(X, y):\n    # multiple by -1 to make positive MAE score instead of neg value returned as sklearn convention\n    return -1 * cross_val_score(RandomForestRegressor(50), \n                                X, y, \n                                scoring = 'neg_mean_absolute_error').mean()\n\n# Identify numeric columns\ndef numeric_cols(data_frame):\n    numeric_cols = [cname for cname in data_frame.columns if \n                                data_frame[cname].dtype in ['int64', 'float64']]\n    return(numeric_cols)\n\n# Identify categorical columns with low cardinality (a small number of distinct values)\ndef low_cardinality_cols(data_frame):\n    low_cardinality_cols = [cname for cname in data_frame.columns if \n                                data_frame[cname].nunique() < 10 and\n                                data_frame[cname].dtype == \"object\"]\n    return(low_cardinality_cols)\n\n# Identify columns with missing data\ndef cols_with_missing(data_frame):\n    cols_with_missing = [cname for cname in data_frame.columns \n                                 if data_frame[cname].isnull().any()]\n    return(cols_with_missing)\n\n# Read core training and test data\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\n\n# Drop houses where the target is missing\ntrain_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n\n# get statistical properties of the data\n#print(train_data.describe())\n\n# view first 5 rows of the data\n#train_data.head(5)\n\n# view the columns in the data \n#print(train_data.columns)\n\n# Check size of data (1460 entries across 81 columns)\n#train_data.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a455dd9e-5003-4199-a160-5e2403466a26",
        "_uuid": "a0dd791c67d66fb04c96e849c668b9689498fe0c"
      },
      "cell_type": "markdown",
      "source": "Some quick partial dependency graphs."
    },
    {
      "metadata": {
        "_cell_guid": "2e087d48-0c45-4f87-a1cc-500de8fd4fe7",
        "collapsed": true,
        "_uuid": "474dc2e9ddbceaf85a5b23bc56c4b274553e0e5c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "cols_to_use = ['FullBath','OverallQual','LotArea','1stFlrSF','2ndFlrSF','YearBuilt']\n#cols_to_use = low_cardinality_cols(train_data) + numeric_cols(train_data)\ny = train_data.SalePrice\nX = train_data[cols_to_use]\n#X = X.drop(['SalePrice'], axis=1)\n#X = pd.get_dummies(X)\nmy_imputer = Imputer()\nX = my_imputer.fit_transform(X)\n\nmy_model = GradientBoostingRegressor()\nmy_model.fit(X, y)\nmy_plots = plot_partial_dependence(my_model,       \n                                   features=[0, 1, 2, 3, 4, 5], # column to plot\n                                   X=X, # raw predictors data\n                                   feature_names=cols_to_use, # labels on graphs\n                                   grid_resolution=10) # number of values to plot on x axis",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7efdd57c-e4fb-4519-80c8-1fed1bedaf49",
        "_uuid": "0dfa10b0ce4c4b8b891d0664398452ed487554a1"
      },
      "cell_type": "markdown",
      "source": "Split data into training data and validation data for the decision tree model."
    },
    {
      "metadata": {
        "_cell_guid": "bbf2c931-37bb-448c-92ac-547581560bfa",
        "collapsed": true,
        "_uuid": "2ef80d1e50e23ae80e8405ad7f3601636ceafb43",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# specify columns to use for fitting decision tree model\npredictor_list = ['FullBath','OverallQual','LotArea','1stFlrSF','2ndFlrSF','YearBuilt']\n\n# define x and y\ny = train_data.SalePrice\nX = train_data[predictor_list]\n\n# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8bfc6ae4-3aef-427e-b986-87fb461f4181",
        "_uuid": "2ab0ad4baee8fc3f92c575bf5e20d99dd33c1c39"
      },
      "cell_type": "markdown",
      "source": "Compare MAE (mean absolute error) with differing values of max_leaf_nodes...this basically tests different error based on the depth of the tree to find the sweet spot between overfitting and underfitting."
    },
    {
      "metadata": {
        "_kg_hide-input": false,
        "_cell_guid": "a1212716-b56a-4300-9d71-c91cffeb35e6",
        "collapsed": true,
        "_uuid": "38509284a9e39a9bdad24a2bb73441d7b7abb5f6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# compare MAE (mean absolute error) with differing values of max_leaf_nodes...\n# this basically tests different error based on the depth of the tree to find \n# the sweet spot between overfitting and underfitting\nbest_mae = float(\"inf\") # set to infinity\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    current_mae = get_decision_depth_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    if current_mae < best_mae:\n        best_max_leaf_nodes = max_leaf_nodes\n        best_mae = current_mae\n    print(\"Max leaf nodes: {}  \\t\\t Mean Absolute Error:  {}\".format(max_leaf_nodes, current_mae))\nprint(\"------------------------------------------------\")\nprint(\"Best max leaf nodes: {}\".format(best_max_leaf_nodes))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3ad75142-7db6-4901-829d-40a122642715",
        "_uuid": "5d74d326f5d6727eb0cc4c75ad17b8aa105c779b"
      },
      "cell_type": "markdown",
      "source": "Define the decision tree model and review it's MAE..."
    },
    {
      "metadata": {
        "_cell_guid": "9556f18d-f4b8-4546-a42f-247687190a91",
        "collapsed": true,
        "_uuid": "6c5921fbde5e8afc316c74678685af06607c0128",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# define the decision tree model\ndecision_tree_model = DecisionTreeRegressor(max_leaf_nodes=best_max_leaf_nodes, random_state=0)\n# train the model\ndecision_tree_model.fit(train_X,train_y)\n# run predictions against validation data to determine the error \n# of the decision tree \npredicted_home_prices = decision_tree_model.predict(val_X)\ndecision_mae = mean_absolute_error(val_y, predicted_home_prices)\nprint(\"Decision tree MAE: {}\".format(decision_mae))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "21183730-a8b4-496f-807c-95d02b29285c",
        "collapsed": true,
        "_uuid": "6a6430fd3134320f0a4c4d8f90196083eaa57100",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# a quick sample of predictions against the validation data for decision tree\nprint(\"Making predictions for the following houses:\")\nprint(val_X.head(2))\nprint(\"------------------------------------------------\")\nprint(\"The predictions are\")\nprint(decision_tree_model.predict(val_X.head(2)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f6d5006d-cc1e-4054-92cf-ebb7daf9c300",
        "_uuid": "53874e5b6c579ba8f095e42618dbf6320640b6ef"
      },
      "cell_type": "markdown",
      "source": "Define the random forest model and review its MAE..."
    },
    {
      "metadata": {
        "_cell_guid": "326ae852-0b59-4772-a5a5-4ce97b74fb9d",
        "collapsed": true,
        "_uuid": "616f0f4d29f02811cda39b531e99f16230f46946",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# define the random forest model \nforest_model = RandomForestRegressor()\n# train the model\nforest_model.fit(train_X, train_y)\n# run predictions against validation data to determine the error \n# of the random forest tree \npredicted_home_prices = forest_model.predict(val_X)\nforest_mae = mean_absolute_error(val_y, predicted_home_prices)\nprint(\"Decision tree MAE: {}\".format(decision_mae))\nprint(\"Random Forest MAE: {}\".format(forest_mae))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "46d24024-8500-46f0-9968-fd82858d48e8",
        "collapsed": true,
        "_uuid": "4839312d133b7c12be3eb7d8389e6c3e3b736ef0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# a quick sample of predictions against the validation data for forest tree\nprint(\"Making predictions for the following 5 houses:\")\nprint(val_X.head(2))\nprint(\"------------------------------------------------\")\nprint(\"The predictions are\")\nprint(forest_model.predict(val_X.head(2)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "81c9ca85-6587-4c93-8fb6-532286143baa",
        "collapsed": true,
        "_uuid": "69f1fb3554b8333e7d6d48ee72f658567094288a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# reset data based on all numeric predictors\nmycols = low_cardinality_cols(train_data) + numeric_cols(train_data)\n# If I use one hot on my final model then I'll need to leverage the .align method between train and test data\nX = train_data[mycols]\nX = pd.get_dummies(X)\nX = X.drop(['SalePrice'], axis=1)\ntrain_X, val_X, train_y, val_y = train_test_split  (X, \n                                                    y,\n                                                    train_size=0.7, \n                                                    test_size=0.3, \n                                                    random_state=0)\nX.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8fe6a725-b67e-46d7-853f-84c3b29893ad",
        "_uuid": "33e7ac2141791c54ea27d491ccf33333229c5cff"
      },
      "cell_type": "markdown",
      "source": "Check MAE of random forest by just dropping columns with nulls..."
    },
    {
      "metadata": {
        "_cell_guid": "d51313bc-2365-4d7c-a314-f1915f94cc15",
        "collapsed": true,
        "_uuid": "031a6243749c521f593d5d23d7cf63c17b6707f5",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# check mae of random forest by just dropping columns with nulls\nreduced_train_X = train_X.drop(cols_with_missing(X), axis=1)\nreduced_val_X  = val_X.drop(cols_with_missing(X), axis=1)\nprint(\"Mean Absolute Error from dropping columns with Missing Values:\")\nprint(get_forest_mae(reduced_train_X, reduced_val_X, train_y, val_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "6f3781aa-9ab0-495d-a483-e933d19f2144",
        "_uuid": "b76b6c4fb4fa011bbe3f64f23038a119600e50c3"
      },
      "cell_type": "markdown",
      "source": "Check MAE of random forest with imputation..."
    },
    {
      "metadata": {
        "_cell_guid": "fcba8faf-dcdc-4bbe-bc77-aca66d99036e",
        "collapsed": true,
        "_uuid": "8c42019094a1735e8b5c8a0e6937560eb781ea06",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# check mae of random forest with imputation\nmy_imputer = Imputer()\nimputed_train_X = my_imputer.fit_transform(train_X)\nimputed_val_X = my_imputer.transform(val_X)\nprint(\"Mean Absolute Error from Imputation:\")\nprint(get_forest_mae(imputed_train_X, imputed_val_X, train_y, val_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ffb80bb7-049d-45e5-8ecb-dafd9524cf63",
        "_uuid": "0af4099ad3547a894612fdab4bf63be070984134"
      },
      "cell_type": "markdown",
      "source": "Check MAE of random forest with imputation while tracking imputed columns..."
    },
    {
      "metadata": {
        "_cell_guid": "c63e157f-a0c0-4c92-8f1b-cd4a638c3c72",
        "collapsed": true,
        "_uuid": "bd40ff36cdf8dd1e3fcc97f3c3eb6098059d2063",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# check mae of random forest with imputation while tracking imputed columns\nimputed_train_X_plus = train_X.copy()\nimputed_val_X_plus = val_X.copy()\n\nfor col in cols_with_missing(imputed_train_X_plus):\n    imputed_train_X_plus[col + '_was_missing'] = imputed_train_X_plus[col].isnull()\n    imputed_val_X_plus[col + '_was_missing'] = imputed_val_X_plus[col].isnull()\n\n# Imputation\nmy_imputer = Imputer()\nimputed_train_X_plus = my_imputer.fit_transform(imputed_train_X_plus)\nimputed_val_X_plus = my_imputer.transform(imputed_val_X_plus)\n\nprint(\"Mean Absolute Error from Imputation while Tracking What Was Imputed:\")\nprint(get_forest_mae(imputed_train_X_plus, imputed_val_X_plus, train_y, val_y))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "13066480-68f4-4678-895b-ca2b5f3a0add",
        "_uuid": "937314f52f7286926af2b752c90b17959138a6d1"
      },
      "cell_type": "markdown",
      "source": "Check MAE of XGBoost (Gradient Boosted Decision Trees)..."
    },
    {
      "metadata": {
        "_cell_guid": "3e0d57af-27aa-43f1-9a39-7cd57d212656",
        "collapsed": true,
        "_uuid": "2b3394fda0658059ca9b32d9342a3e2c7c4f49be",
        "trusted": false
      },
      "cell_type": "code",
      "source": "y = train_data.SalePrice\nX = train_data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\ntrain_X, test_X, train_y, test_y = train_test_split(X.as_matrix(), \n                                                    y.as_matrix(), \n                                                    test_size=0.25)\n\n#impute missing values\nmy_imputer = Imputer()\ntrain_X = my_imputer.fit_transform(train_X)\ntest_X = my_imputer.transform(test_X)\n\n# n_estimators specifies the number of fitting rounds to attempt\n# a small learning_rate deteriorates the value of more runs which helps with overfitting\n# n_jobs increases the number of cores (parallelism) in the computation to improve performance\nmy_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs = 2)\n# Add silent=True to avoid printing out updates with each cycle\n# early_stopping_rounds stops the model fitting once there are multiple rounds of similar error\n# n_estimators above is overruled by the early_stopping_rounds setting\nmy_model.fit(train_X, train_y, early_stopping_rounds=5, \n             eval_set=[(test_X, test_y)], verbose=False)\n\n# make predictions\npredictions = my_model.predict(test_X)\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, test_y)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "202c7ffa-1111-4b13-97dc-8119fb701250",
        "_uuid": "bec92d903e3f32b29d63655276f91e2e4bef7228"
      },
      "cell_type": "markdown",
      "source": "**Run a Pipeline to simplify along with streamlined cross validation**"
    },
    {
      "metadata": {
        "scrolled": false,
        "_cell_guid": "2684ec33-e2c5-4299-9fd5-1fc010577faf",
        "collapsed": true,
        "_uuid": "ab2fb1ef50e3ce3b5b95c7015567c7b223c018e1",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# pull all data data into target (y) and predictors (X)\ntrain_y = train_data.SalePrice\nfinal_train_X_cols = low_cardinality_cols(train_data) + numeric_cols(train_data)\ntrain_X = train_data[final_train_X_cols]\ntrain_X = pd.get_dummies(train_X)\ntrain_X = train_X.drop(['SalePrice'], axis=1)\n\n# Treat the test data in the same way as training data. In this case, pull same columns.\nfinal_test_X_cols = low_cardinality_cols(test_data) + numeric_cols(test_data)\ntest_X = test_data[final_test_X_cols]\ntest_X = pd.get_dummies(test_X)\n\n# inner join the data to ensure the exact columns included are aligned\ntrain_X, test_X = train_X.align(test_X,\n                                join='inner', \n                                axis=1)\n\n#fit the model with imputation at the same time using a pipeline\nmy_pipeline = make_pipeline(Imputer(), RandomForestRegressor())\nscores = cross_val_score(my_pipeline, X, y, scoring='neg_mean_absolute_error')\n# average the three scores and make it a positive number\nprint('Mean Absolute Error %2f' %(-1 * scores.mean()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "71e4caa2-eba6-4b38-9595-a7ec2877891c",
        "collapsed": true,
        "_uuid": "47f8c420ded1649d7a5193f4e581c1e349a74a6f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# train the model\nmy_pipeline.fit(train_X, train_y)\n\n# Use the model to make predictions\nfinal_predicted_prices = my_pipeline.predict(test_X)\n\n# look at the predicted prices to ensure we have something sensible.\nprint(final_predicted_prices)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}